{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"../../Dataset/FER2013/test\"\n",
    "train_file_path = \"../../Dataset/FER2013/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = Image.fromarray(image.squeeze())  # Remove color channels for grayscale\n",
    "    image = image.resize((64, 64), Image.BILINEAR)  # Resize to 64x64\n",
    "    return np.expand_dims(np.array(image), axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_image)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_file_path,\n",
    "    target_size=(64, 64),  # or any size that your model expects\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_file_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simplified_model(conv_1_filters, conv_2_filters, \n",
    "                           conv_1_kernel, conv_2_kernel,\n",
    "                           dropout_1, dropout_2, dense_units, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(conv_1_filters, kernel_size=conv_1_kernel, activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(dropout_1))\n",
    "\n",
    "    model.add(Conv2D(conv_2_filters, kernel_size=conv_2_kernel, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(dropout_2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_simplified_model(\n",
    "    conv_1_filters=32, conv_2_filters=64, \n",
    "    conv_1_kernel=3, conv_2_kernel=3, \n",
    "    dropout_1=0.5, dropout_2=0.6, \n",
    "    dense_units=1024, \n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history_v1 = model.fit(train_generator, validation_data=test_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Attempt (with Class Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dirs = sorted([d for d in os.listdir(train_file_path) if os.path.isdir(os.path.join(train_file_path, d))])\n",
    "class_counts = {}\n",
    "\n",
    "# Count the number of samples in each class\n",
    "for class_dir in class_dirs:\n",
    "    class_path = os.path.join(train_file_path, class_dir)\n",
    "    class_counts[class_dir] = len(os.listdir(class_path))\n",
    "\n",
    "# Calculate total samples and class weights\n",
    "total_samples = sum(class_counts.values())\n",
    "class_weights = {class_idx: total_samples / (len(class_dirs) * count)\n",
    "                 for class_idx, count in enumerate(class_counts.values())}\n",
    "\n",
    "# Display the class weights with class names\n",
    "for class_idx, class_name in enumerate(class_dirs):\n",
    "    print(f\"Class Index: {class_idx}, Class Name: {class_name}, Weight: {class_weights[class_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_simplified_model(\n",
    "    conv_1_filters=32, conv_2_filters=64, \n",
    "    conv_1_kernel=3, conv_2_kernel=3, \n",
    "    dropout_1=0.5, dropout_2=0.6, \n",
    "    dense_units=1024, \n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history_v2 = model.fit(train_generator, validation_data=test_generator, epochs=10, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next attempt could try to change learning rate as the accuracy is slowing down which means going to plateau, more epochs also possible to see if accuracy improve further. Regularization, data augmentation could be tried as well. For more details, check GPU Training on GPT4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Attempt (with Class Weight, more Epochs, Early Stopping and Learning Rate adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = build_simplified_model(\n",
    "    conv_1_filters=32, conv_2_filters=64, \n",
    "    conv_1_kernel=3, conv_2_kernel=3, \n",
    "    dropout_1=0.5, dropout_2=0.6, \n",
    "    dense_units=1024, \n",
    "    optimizer= Adam(learning_rate=0.0005) \n",
    ")\n",
    "\n",
    "\n",
    "history_v2 = model.fit(train_generator, validation_data=test_generator, epochs=20, class_weight=class_weights, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Attempt (SGD optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_112 (Conv2D)         (None, 32, 32, 32)        2080      \n",
      "                                                                 \n",
      " batch_normalization_112 (B  (None, 32, 32, 32)        128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_112 (Activation  (None, 32, 32, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 16, 16, 32)        65568     \n",
      "                                                                 \n",
      " batch_normalization_113 (B  (None, 16, 16, 32)        128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_113 (Activation  (None, 16, 16, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 8, 8, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_114 (B  (None, 8, 8, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_114 (Activation  (None, 8, 8, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 4, 4, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_115 (B  (None, 4, 4, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_115 (Activation  (None, 4, 4, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 2, 2, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_116 (B  (None, 2, 2, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_116 (Activation  (None, 2, 2, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_117 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_117 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_118 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_118 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_119 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_119 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_120 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_120 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_121 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_121 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_122 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_122 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_123 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_123 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_124 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_124 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_125 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_125 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 1, 1, 32)          65568     \n",
      "                                                                 \n",
      " batch_normalization_126 (B  (None, 1, 1, 32)          128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_126 (Activation  (None, 1, 1, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 1, 1, 7)           10983     \n",
      "                                                                 \n",
      " batch_normalization_127 (B  (None, 1, 1, 7)           28        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_127 (Activation  (None, 1, 1, 7)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 933019 (3.56 MB)\n",
      "Trainable params: 932045 (3.56 MB)\n",
      "Non-trainable params: 974 (3.80 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "def build_model_1():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first convolutional layer with input shape\n",
    "    model.add(Conv2D(32, kernel_size=(8, 8), strides=(2, 2), padding='same', input_shape=(64, 64, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Add the remaining convolutional layers\n",
    "    for _ in range(14):  # one less because we already added the first layer\n",
    "        model.add(Conv2D(32, kernel_size=(8, 8), strides=(2, 2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # Last Convolutional layer with 7 filters\n",
    "    model.add(Conv2D(7, kernel_size=(7, 7), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Flatten and add Softmax output layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model_1 = build_model_1()\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Now you can call model.summary()\n",
    "model_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "898/898 [==============================] - 18s 17ms/step - loss: 1.9523 - accuracy: 0.1390 - val_loss: 1.9344 - val_accuracy: 0.1846\n",
      "Epoch 2/140\n",
      "898/898 [==============================] - 15s 16ms/step - loss: 1.9262 - accuracy: 0.1683 - val_loss: 1.9185 - val_accuracy: 0.2246\n",
      "Epoch 3/140\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.9106 - accuracy: 0.2036 - val_loss: 1.8905 - val_accuracy: 0.2001\n",
      "Epoch 4/140\n",
      "898/898 [==============================] - 15s 16ms/step - loss: 1.8962 - accuracy: 0.2428 - val_loss: 1.8822 - val_accuracy: 0.2901\n",
      "Epoch 5/140\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.8873 - accuracy: 0.2625 - val_loss: 1.8527 - val_accuracy: 0.3022\n",
      "Epoch 6/140\n",
      "898/898 [==============================] - 15s 16ms/step - loss: 1.8760 - accuracy: 0.2732 - val_loss: 1.8553 - val_accuracy: 0.2949\n",
      "Epoch 7/140\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.8580 - accuracy: 0.2624 - val_loss: 1.8331 - val_accuracy: 0.2699\n",
      "Epoch 8/140\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.8462 - accuracy: 0.2764 - val_loss: 1.8996 - val_accuracy: 0.2371\n",
      "Epoch 9/140\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.8169 - accuracy: 0.2702 - val_loss: 1.8327 - val_accuracy: 0.2485\n",
      "Epoch 10/140\n",
      "897/898 [============================>.] - ETA: 0s - loss: 1.7850 - accuracy: 0.2817Restoring model weights from the end of the best epoch: 5.\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 1.7846 - accuracy: 0.2817 - val_loss: 1.8069 - val_accuracy: 0.2595\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(\n",
    "    train_generator,\n",
    "    epochs=140,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sgd_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    for _ in range(15):\n",
    "        model.add(Conv2D(32, kernel_size=(8,8), strides=(2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(7, kernel_size=(7, 7), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "sgd_model = build_sgd_model()\n",
    "\n",
    "sgd_model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model.fit(train_generator, validation_data=test_generator, epochs=140, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
