\section{Background and Significance}
This project explores the relationship between technology and mental health by developing a web application that utilizes \gls{fer} to personalize music therapy sessions.
The application tries to identify emotional signs from facial expressions by combining cognitive science and \gls{ml}, and it suggests music that might raise user's mood.
This innovative approach might help to solve the practical problem of improving emotional well-being in areas where traditional therapy may not be available.

\section{Problem Statement}
The idea of this project lies in its potential to provide immediate, personalized therapeutic support.
Although the benefits of music therapy for mental health are well known, but integrating it wil real-time emotion recognition technology provides an advanced approach for delivering presonalized care that changes depending on the user's emotional state.

\section{Objectives}
The main objectives of the project were to:
\begin{itemize}
    \item Develop a \gls{fer} system.
    \item Integrate this system with music therapy principles.
    \item Create a user-friendly interface that allows interaction and enhances user engagement.
\end{itemize}

\section{Literature Review Findings Summary}
From the literature review, many studies have been conducted separately on emotion detection and music therapy, not much have tried to combine the two for use in real-time applications.
This gap highlights the project's imagination and its potential value to the fields of psychology and technology.

\section{Approach and Methodology}
The approaches to solve this problem:
\begin{itemize}
    \item Designing and training machine learning models to accurately recognize human emotions from facial expressions.
    \item Developing a system that uses emotional signs to generate playlist that corresponds to user's emotional state.
    \item Implementing the system within a web application to ensure accessibility and ease of use.
\end{itemize}

\section{Project Outcomes}
The result of the project is a fully functional web  application that identifies emotions and generate playlists based on user's emotional state.
The system effectively integrates a music recommendation interface with an advanced \gls{ml} algorithms for emotion recognition.
While the application has went through testing to ensure its reliability and efficacy, but it has not yet been refined based on user feedback, which is a possible area for future iterations.

\section{Report Structure}
The report is structured as follow:
\begin{itemize}
    \item \textbf{Chapter 2: Literature Review}: Provides an analysis of the studies on music therapy, emotion detection technology, and their applications in mental health.
    \item \textbf{Chapter 3: Requirements}: Details the functional and non-functional requirements that guided the development of the project.
    \item \textbf{Chapter 4: Methodology}: Discusses multiple methodologies and justify the reason of selecting the specific methodologies which employed in developing the \gls{fer} model and the music recommendation system.
    \item \textbf{Chapter 5: Design}: Describes the system design such as the architecture, user interface of the web application, the model architecture such as the layers.
    \item \textbf{Chapter 6: Implementation}: Explain the steps taken in the implementation of building the \gls{ml} model and web application.
    \item \textbf{Chapter 7: Project Evaluation}: Evaluates the trained models and the developed application, discusses limitations and potential improvements.
    \item \textbf{Chapter 8: Conclusion and Future Work}: Concludes the report with a summary of the project outcomes, and outlines possible future improvements to enhance the system's capabilities.
\end{itemize}
